{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KIZekoYKaPr"
      },
      "source": [
        "# Stock Market Predictor\n",
        "\n",
        "### Background\n",
        "\n",
        "The United States stock market provides investors with the ability to invest in small, fractional shares of companies in a relatively liquid environment. This provides one of the most well-established ways of earning investment income and building long term wealth. Unfortunately, there has traditionally been an uneven playing field between the average investor and high-powered trading firms. Fortunately, roughly five years ago, most of the major brokerage firms removed trade fees for individual investors, creating an environment where an individual investor now has an opportunity to generate returns that are in the same ballpark of the major firms.\n",
        "\n",
        "\n",
        "These major investment firms, such as Morgan Stanley and Blackrock, are able to consistently post higher returns than the average investor through the use of powerful analytics and high-frequency trading. This project will focus on making some of those analytical tools available to the average investor. High-frequency trading is still not achievable for most individual traders due to hardware constraints. If this tool can help investors increase their returns by even 1%, this can go a long way towards helping people reach financial freedom earlier, and being able to take more control of their lives.\n",
        "\n",
        "### Topic\n",
        "\n",
        "This project will utilize publicly available stock market data, such as volume, open/close prices, and high/low prices, along with other features that I will engineer to create a system that can accurately predict if a given stock will increase or decrease the next trading day. This will be difficult as the stock market is notoriously noisy and volatile and because of this, the system will be designed to focus on stocks that have been in existence for at least 10 years.\n",
        "\n",
        "\n",
        "Most stock prediction systems utilize close prices and label a stock a “buy” if tomorrow's close price is higher than today’s. This creates a potential timeline issue, as most of these systems simply predict if a stock will go up or down, not when it will go up or down by. I will base my buy and sell signals on the difference between tomorrow’s estimated open cost and tomorrow’s estimated close cost. This will increase the error rate (since two predictions are being made instead of one) but will provide a clearly defined time table.\n",
        "\n",
        "### Strategy\n",
        "\n",
        "The first step in this process will be to import public stock data from Yahoo Finance by ticker symbol for the last ten years. To begin cleaning the data I will drop the adjusted close column. This is not needed since the goal is to  predict one day in the future. The stock will be labeled as follows:\n",
        "\n",
        "\n",
        "Buy: if tomorrow’s close price is predicted higher than tomorrow’s open price\n",
        "Sell: if tomorrow’s close price is predicted lower than tomorrow’s open price\n",
        "\n",
        "\n",
        "This creates the need to build a system that effectively predicts both the open and close price of a stock for the following day. These might not be the exact same system, although I would expect that will be quite similar.\n",
        "\n",
        "\n",
        "Next, I will begin feature engineering. I will add returns and volatility over one, two, and three month periods in a style similar to what Devpark0506 did in his Kaggle notebook titled “JPX Stock Market Analysis & Prediction with LGBM.” Then I will create 10 and 40 day exponential moving averages (ema) and an average price oscillator (apo) similar to what Sabestien Donadio recommends in his book “Learn Algorithmic Trading.\" These features add some of the “standard” analytical calculations that a trader might run for a stock. Finally, I will impute labels that indicate wether a stock was a 'Buy' or 'Sell' for that day. This will provide another feature for our algorithms to work with.\n",
        "\n",
        "Then the splitting must occur. This will be done in two 'batches'. The first will be for the open price prediction where all of the data for a day are the features and the label is the open price from the following day. The second will be for the close price prediction where all of the data for the day are the features and the label is the next day's close price. These will then be seperately split into train and test sets, and the train set will be further split into a train set and a validation set for the neural network.\n",
        "\n",
        "\n",
        "Once these features are developed, I will begin to train both neural networks and random forests on the training set. I will create neural networks and random forests to predict tomorrow’s open and tomorrow’s close prices. While the ultimate result of this project will be a signal, these machine learning systems are going to be used for regression. I will run these on the test set in order to get the RMSE. This is how I will be able to determine which program is more successful and should be deployed.\n",
        "\n",
        "\n",
        "In order to create a system that is usable by an individual trader, I will use the system with the best combination of runtime and low RMSE. This system will send the trader a buy signal if the system predicts that tomorrow’s close will be higher than tomorrow’s open and a sell signal if the opposite is true. Further, the system will provide the combined RMSE of the prediction (at least for the Random Forest) so that the trader can understand the potential for the prediction to be worng. The system is designed for an individual trader to run the prediction after hours and put an order in that will resolve immediately upon market open the next day. Finally, an interactive webpage will be created in which a trader can input a stock ticker symbol and get the signal in return. This webapp can be found at daytradingstocksignalsystem.streamlit.app\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d503Sc00KiNF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUj3Yyj7KbCY"
      },
      "outputs": [],
      "source": [
        "#Standard + Necessary Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import scipy as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_datareader import data as pdr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from hyperopt import tpe, hp, Trials\n",
        "from hyperopt.fmin import fmin\n",
        "\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZgHC4xUKt3R"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBPDsfwBKq9m"
      },
      "outputs": [],
      "source": [
        "#Function that will get data for the provided stock and date range\n",
        "def get_data(ticker, start_date, end_date):\n",
        "    data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
        "    data = data.drop(columns = ['Adj Close'])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP_gnowSKxAd"
      },
      "outputs": [],
      "source": [
        "#Most of this cell comes from Devpark0506's notebook called \"JPX Stock Market Analysis & Prediction with LGBM\"\n",
        "def add_returns_volatility(df):\n",
        "    #adding monthly returns using 20 day periods as months and the percent change over that period\n",
        "    df['1_month_returns'] = df['Close'].pct_change(20)\n",
        "    df['2_month_returns'] = df['Close'].pct_change(40)\n",
        "    df['3_month_returns'] = df['Close'].pct_change(60)\n",
        "\n",
        "    #adding volatility using standard deviation\n",
        "    df['1_month_vol'] = (np.log(df['Close']).diff().rolling(20).std())\n",
        "    df['2_month_vol'] = (np.log(df['Close']).diff().rolling(40).std())\n",
        "    df['3_month_vol'] = (np.log(df['Close']).diff().rolling(60).std())\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tISv0a-gKzAJ"
      },
      "outputs": [],
      "source": [
        "#this will add emas and apo to our database.\n",
        "#Most of the ideas in this function come from Learn Algorithmic Trading by Sabestien Donadio\n",
        "def add_emas(df):\n",
        "    close = df['Close']\n",
        "    apo_values = []\n",
        "    ema_fast_values = []\n",
        "    ema_slow_values = []\n",
        "    price_history = []\n",
        "    ema_fast = 0\n",
        "    ema_slow = 0\n",
        "\n",
        "    for close_price in close:\n",
        "        price_history.append(close_price)\n",
        "        if len(price_history) > 20:\n",
        "            del(price_history[0])\n",
        "\n",
        "        #This idea is from Learn Algorithmic Trading by Sabestien Donadio. It will be used for our volatility measure\n",
        "        sma = stats.mean(price_history)\n",
        "        variance = 0\n",
        "        for hist_price in price_history:\n",
        "            variance = variance + ((hist_price - sma) ** 2)\n",
        "\n",
        "        #this idea for a volatility factor comes from Learn Algorithmic Trading by Sabestien Donadio\n",
        "        stdev = math.sqrt(variance / len(price_history))\n",
        "        stdev_factor = stdev/15\n",
        "        if stdev_factor == 0:\n",
        "            stdev_factor = 1\n",
        "\n",
        "\n",
        "        if (ema_fast == 0): # first observation\n",
        "            ema_fast = close_price\n",
        "            ema_slow = close_price\n",
        "        else:\n",
        "            #calculating ema with a smoothing factor and the stdev_factor which is a way to account for volatility\n",
        "            ema_fast = (close_price - ema_fast) * (2/(10+1)) *stdev_factor + ema_fast\n",
        "            ema_slow = (close_price - ema_slow) * (2/(40+1)) *stdev_factor + ema_slow\n",
        "\n",
        "        ema_fast_values.append(ema_fast)\n",
        "        ema_slow_values.append(ema_slow)\n",
        "\n",
        "        #calculating apo as the difference between fast and slow emas\n",
        "        apo = ema_fast - ema_slow\n",
        "        apo_values.append(apo)\n",
        "\n",
        "    df = df.assign(fast_ema = pd.Series(ema_fast_values, index=df.index))\n",
        "    df = df.assign(slow_ema = pd.Series(ema_slow_values, index=df.index))\n",
        "    df = df.assign(APO = pd.Series(apo_values, index=df.index))\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MFrmcHrK1fo"
      },
      "outputs": [],
      "source": [
        "#this function adds labels to the data\n",
        "def add_labels(df):\n",
        "    day_change = df['Close'] - df['Open']\n",
        "    percent_day_change = (df['Close'] - df['Open']) / df['Open']\n",
        "    labels = []\n",
        "\n",
        "    for change in percent_day_change:\n",
        "        #stock is a buy if it closes higher than it opens\n",
        "        if change > 0:\n",
        "            labels.append(1)\n",
        "        #a sell if the stock closes lower than it opens\n",
        "        else:\n",
        "            labels.append(0)\n",
        "\n",
        "    df['day_change'] = day_change\n",
        "    df['percent_day_change'] = percent_day_change\n",
        "    df['signal'] = labels\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HFWAqerK307"
      },
      "outputs": [],
      "source": [
        "#this function combines all of our previous functions to output a single dataframe with all of our engineered features\n",
        "def clean_data(user_input_symbol, user_input_start_date, user_input_end_date):\n",
        "    data = get_data(user_input_symbol, user_input_start_date, user_input_end_date)\n",
        "    data = add_returns_volatility(data)\n",
        "    data = add_emas(data)\n",
        "    data = add_labels(data)\n",
        "    data = data.fillna(0)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnc7rHp3K-lM"
      },
      "source": [
        "# Dataframe Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "gRqEtnDKK50T",
        "outputId": "74a15a58-51c0-4dff-b859-036833fa0270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Open       High        Low      Close    Volume  \\\n",
              "Date                                                               \n",
              "2013-10-02  26.250000  27.969999  25.400000  27.000000  13845300   \n",
              "2013-10-03  27.129999  31.080000  27.000000  30.209999   2456400   \n",
              "2013-10-04  30.920000  33.540001  30.400000  31.650000   1998100   \n",
              "2013-10-07  31.100000  31.420000  30.020000  30.830000    460400   \n",
              "2013-10-08  30.510000  30.639999  28.080000  28.500000   1101700   \n",
              "...               ...        ...        ...        ...       ...   \n",
              "2023-07-27  20.299999  20.440001  19.660000  19.770000     58800   \n",
              "2023-07-28  19.879999  20.040001  19.629999  19.650000     38000   \n",
              "2023-07-31  19.600000  19.840000  19.590000  19.709999     56100   \n",
              "2023-08-01  19.629999  19.790001  19.260000  19.540001     83400   \n",
              "2023-08-02  19.510000  19.740000  19.290001  19.660000     66300   \n",
              "\n",
              "            1_month_returns  2_month_returns  3_month_returns  1_month_vol  \\\n",
              "Date                                                                         \n",
              "2013-10-02         0.000000         0.000000         0.000000     0.000000   \n",
              "2013-10-03         0.000000         0.000000         0.000000     0.000000   \n",
              "2013-10-04         0.000000         0.000000         0.000000     0.000000   \n",
              "2013-10-07         0.000000         0.000000         0.000000     0.000000   \n",
              "2013-10-08         0.000000         0.000000         0.000000     0.000000   \n",
              "...                     ...              ...              ...          ...   \n",
              "2023-07-27         0.027547         0.062903         0.023822     0.019446   \n",
              "2023-07-28         0.000509         0.051364         0.044102     0.018967   \n",
              "2023-07-31         0.023364         0.071196         0.057971     0.018405   \n",
              "2023-08-01         0.001538         0.028963         0.073037     0.018312   \n",
              "2023-08-02         0.053026         0.069059         0.028781     0.015111   \n",
              "\n",
              "            2_month_vol  3_month_vol   fast_ema   slow_ema       APO  \\\n",
              "Date                                                                   \n",
              "2013-10-02     0.000000     0.000000  27.000000  27.000000  0.000000   \n",
              "2013-10-03     0.000000     0.000000  27.062449  27.016755  0.045694   \n",
              "2013-10-04     0.000000     0.000000  27.170529  27.046041  0.124489   \n",
              "2013-10-07     0.000000     0.000000  27.248727  27.067734  0.180993   \n",
              "2013-10-08     0.000000     0.000000  27.274152  27.075542  0.198610   \n",
              "...                 ...          ...        ...        ...       ...   \n",
              "2023-07-27     0.019904     0.020244  20.038104  25.670282 -5.632178   \n",
              "2023-07-28     0.019932     0.019972  20.035645  25.660050 -5.624405   \n",
              "2023-07-31     0.019744     0.019923  20.033605  25.650047 -5.616443   \n",
              "2023-08-01     0.019202     0.019720  20.030513  25.639781 -5.609268   \n",
              "2023-08-02     0.018464     0.018742  20.028413  25.630688 -5.602274   \n",
              "\n",
              "            day_change  percent_day_change  signal  \n",
              "Date                                                \n",
              "2013-10-02    0.750000            0.028571       1  \n",
              "2013-10-03    3.080000            0.113527       1  \n",
              "2013-10-04    0.730000            0.023609       1  \n",
              "2013-10-07   -0.270000           -0.008682       0  \n",
              "2013-10-08   -2.010000           -0.065880       0  \n",
              "...                ...                 ...     ...  \n",
              "2023-07-27   -0.529999           -0.026108       0  \n",
              "2023-07-28   -0.230000           -0.011569       0  \n",
              "2023-07-31    0.109999            0.005612       1  \n",
              "2023-08-01   -0.089998           -0.004585       0  \n",
              "2023-08-02    0.150000            0.007688       1  \n",
              "\n",
              "[2475 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-dc1cd74d-0f7f-4696-bf9b-d8cd0b84e830\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>1_month_returns</th>\n",
              "      <th>2_month_returns</th>\n",
              "      <th>3_month_returns</th>\n",
              "      <th>1_month_vol</th>\n",
              "      <th>2_month_vol</th>\n",
              "      <th>3_month_vol</th>\n",
              "      <th>fast_ema</th>\n",
              "      <th>slow_ema</th>\n",
              "      <th>APO</th>\n",
              "      <th>day_change</th>\n",
              "      <th>percent_day_change</th>\n",
              "      <th>signal</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>26.250000</td>\n",
              "      <td>27.969999</td>\n",
              "      <td>25.400000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>13845300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>27.129999</td>\n",
              "      <td>31.080000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>30.209999</td>\n",
              "      <td>2456400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.062449</td>\n",
              "      <td>27.016755</td>\n",
              "      <td>0.045694</td>\n",
              "      <td>3.080000</td>\n",
              "      <td>0.113527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>30.920000</td>\n",
              "      <td>33.540001</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>31.650000</td>\n",
              "      <td>1998100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.170529</td>\n",
              "      <td>27.046041</td>\n",
              "      <td>0.124489</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.023609</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>31.100000</td>\n",
              "      <td>31.420000</td>\n",
              "      <td>30.020000</td>\n",
              "      <td>30.830000</td>\n",
              "      <td>460400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.248727</td>\n",
              "      <td>27.067734</td>\n",
              "      <td>0.180993</td>\n",
              "      <td>-0.270000</td>\n",
              "      <td>-0.008682</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>30.510000</td>\n",
              "      <td>30.639999</td>\n",
              "      <td>28.080000</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>1101700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.274152</td>\n",
              "      <td>27.075542</td>\n",
              "      <td>0.198610</td>\n",
              "      <td>-2.010000</td>\n",
              "      <td>-0.065880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-27</th>\n",
              "      <td>20.299999</td>\n",
              "      <td>20.440001</td>\n",
              "      <td>19.660000</td>\n",
              "      <td>19.770000</td>\n",
              "      <td>58800</td>\n",
              "      <td>0.027547</td>\n",
              "      <td>0.062903</td>\n",
              "      <td>0.023822</td>\n",
              "      <td>0.019446</td>\n",
              "      <td>0.019904</td>\n",
              "      <td>0.020244</td>\n",
              "      <td>20.038104</td>\n",
              "      <td>25.670282</td>\n",
              "      <td>-5.632178</td>\n",
              "      <td>-0.529999</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-28</th>\n",
              "      <td>19.879999</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>19.629999</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>38000</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.051364</td>\n",
              "      <td>0.044102</td>\n",
              "      <td>0.018967</td>\n",
              "      <td>0.019932</td>\n",
              "      <td>0.019972</td>\n",
              "      <td>20.035645</td>\n",
              "      <td>25.660050</td>\n",
              "      <td>-5.624405</td>\n",
              "      <td>-0.230000</td>\n",
              "      <td>-0.011569</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-31</th>\n",
              "      <td>19.600000</td>\n",
              "      <td>19.840000</td>\n",
              "      <td>19.590000</td>\n",
              "      <td>19.709999</td>\n",
              "      <td>56100</td>\n",
              "      <td>0.023364</td>\n",
              "      <td>0.071196</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.018405</td>\n",
              "      <td>0.019744</td>\n",
              "      <td>0.019923</td>\n",
              "      <td>20.033605</td>\n",
              "      <td>25.650047</td>\n",
              "      <td>-5.616443</td>\n",
              "      <td>0.109999</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-01</th>\n",
              "      <td>19.629999</td>\n",
              "      <td>19.790001</td>\n",
              "      <td>19.260000</td>\n",
              "      <td>19.540001</td>\n",
              "      <td>83400</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.028963</td>\n",
              "      <td>0.073037</td>\n",
              "      <td>0.018312</td>\n",
              "      <td>0.019202</td>\n",
              "      <td>0.019720</td>\n",
              "      <td>20.030513</td>\n",
              "      <td>25.639781</td>\n",
              "      <td>-5.609268</td>\n",
              "      <td>-0.089998</td>\n",
              "      <td>-0.004585</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-02</th>\n",
              "      <td>19.510000</td>\n",
              "      <td>19.740000</td>\n",
              "      <td>19.290001</td>\n",
              "      <td>19.660000</td>\n",
              "      <td>66300</td>\n",
              "      <td>0.053026</td>\n",
              "      <td>0.069059</td>\n",
              "      <td>0.028781</td>\n",
              "      <td>0.015111</td>\n",
              "      <td>0.018464</td>\n",
              "      <td>0.018742</td>\n",
              "      <td>20.028413</td>\n",
              "      <td>25.630688</td>\n",
              "      <td>-5.602274</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.007688</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2475 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc1cd74d-0f7f-4696-bf9b-d8cd0b84e830')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0980a6a2-2197-4996-8199-325f29f4d959\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0980a6a2-2197-4996-8199-325f29f4d959')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0980a6a2-2197-4996-8199-325f29f4d959 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc1cd74d-0f7f-4696-bf9b-d8cd0b84e830 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc1cd74d-0f7f-4696-bf9b-d8cd0b84e830');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = clean_data('RMAX', '2013-08-02', '2023-08-03')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlyBA-c3LHBE"
      },
      "source": [
        "# Train Test Splitting/Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ilPU2hLEBX"
      },
      "outputs": [],
      "source": [
        "#creating labels and features dataframes for models predicting tomorrow's open\n",
        "open_labels = data['Open'].shift(-1).fillna(data['Open'].iloc[-1])\n",
        "open_features = data.drop(['Open'], axis = 1)\n",
        "\n",
        "#creating labels and feaatures dataframes for models predictings tomorrow's close\n",
        "close_labels = data['Close'].shift(-1).fillna(data['Close'].iloc[-1])\n",
        "close_features = data.drop(['Close'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NM84vkhLJTb"
      },
      "outputs": [],
      "source": [
        "#creating train/test dataframes for random forest training\n",
        "x_train_open, x_test_open, y_train_open, y_test_open = train_test_split(open_features, open_labels, test_size = 0.2)\n",
        "x_train_close, x_test_close, y_train_close, y_test_close = train_test_split(close_features,\n",
        "                                                                            close_labels, test_size = 0.2)\n",
        "\n",
        "#creating training and valid sets for neural net creation\n",
        "x_train_open_nn, x_valid_open, y_train_open_nn, y_valid_open = train_test_split(x_train_open, y_train_open)\n",
        "x_train_close_nn, x_valid_close, y_train_close_nn, y_valid_close = train_test_split(x_train_close, y_train_close)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiating a scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#creating scaled dataframes for future use with the neural network\n",
        "x_train_open_nn = scaler.fit_transform(x_train_open_nn)\n",
        "x_valid_open = scaler.fit_transform(x_valid_open)\n",
        "\n",
        "x_train_close_nn = scaler.fit_transform(x_train_close_nn)\n",
        "x_valid_close = scaler.fit_transform(x_valid_close)\n",
        "\n",
        "scaled_open_features = scaler.fit_transform(open_features)\n",
        "scaled_close_features = scaler.fit_transform(close_features)\n",
        "\n",
        "scaled_x_test_open = scaler.fit_transform(x_test_open)\n",
        "scaled_x_test_close = scaler.fit_transform(x_test_close)"
      ],
      "metadata": {
        "id": "s17L8wNOaVBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBO-O8wqBnt4"
      },
      "source": [
        "# Random Forest Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtf-FraaBqhX"
      },
      "source": [
        "## Open Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gg41pYmBpr7",
        "outputId": "41702252-8fa0-40e6-a960-c23752a7798d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error is: 0.38846089908809445\n"
          ]
        }
      ],
      "source": [
        "#Creating the first random forest model to operate as a baseline\n",
        "rnd_for_open = RandomForestRegressor()\n",
        "rnd_for_open.fit(x_train_open, y_train_open)\n",
        "\n",
        "#Generating predictions\n",
        "pred_rf_open = rnd_for_open.predict(x_test_open)\n",
        "\n",
        "#Getting RMSE score\n",
        "print('Root mean squared error is:', np.sqrt(mean_squared_error(y_test_open, pred_rf_open)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NEEuTKWB3Ef"
      },
      "source": [
        "This provides us with a baseline to work with. A completely untuned model has a root mean squared error of 0.3885"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Y89DLmulBl"
      },
      "source": [
        "### Hypertuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For hypertuning I will try using two different methods. First I will implement the more \"modern\" hyperopt style. This has the benefit of working off of a truly automated coding format, meaning that there is no input needed in between runnings. This is more promising for use on the deployed system. It is worth noting that a lot of the code for implementing this comes from Viraj Bagal's wonderful Kaggle notebook titled \"EDA, XGB,Random Forest Parameter tuning-hyperopt\".\n",
        "\n",
        "Then I will try to more traditional GridSearchCV method. It will be interesting to see if this produces better results with periodic input from a human (me).\n",
        "\n",
        "Above all, it is important to remember that the purpose of this is to create a system useable by day traders. So, a method that improves results but takes 2 hours to run on a standard computer is not practical."
      ],
      "metadata": {
        "id": "DqyShc2rviD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a function that tells hyperopt what to work with\n",
        "def objective(params):\n",
        "  n_estimators = int(params['n_estimators'])\n",
        "  max_depth = int(params['max_depth'])\n",
        "  min_samples_split = int(params['min_samples_split'])\n",
        "  min_samples_leaf = int(params['min_samples_leaf'])\n",
        "  rf_open_tuned = RandomForestRegressor(n_estimators = n_estimators,\n",
        "                                        max_depth = max_depth,\n",
        "                                        min_samples_split = min_samples_split,\n",
        "                                        min_samples_leaf = min_samples_leaf)\n",
        "  rf_open_tuned.fit(x_train_open, y_train_open)\n",
        "  pred_rf_open_tuned = rf_open_tuned.predict(x_test_open)\n",
        "  score = np.sqrt(mean_squared_error(y_test_open, pred_rf_open_tuned))\n",
        "  return score\n",
        "\n",
        "#creating a function that tells hyperopt what space to optimize within\n",
        "def optimize(trial):\n",
        "  params = {\n",
        "      'n_estimators':hp.uniform('n_estimators', 100, 750),\n",
        "      'max_depth':hp.uniform('max_depth', 2, 75),\n",
        "      'min_samples_split':hp.uniform('min_samples_split', 2, 6),\n",
        "      'min_samples_leaf':hp.uniform('min_samples_leaf', 1, 5)}\n",
        "\n",
        "#Timeout is set to 120 sec. This can be decreased for fast tuning, or increased for slow tuning\n",
        "  best = fmin(fn=objective, space=params, algo = tpe.suggest, trials = trial, max_evals=200, timeout = 120)\n",
        "\n",
        "  return best"
      ],
      "metadata": {
        "id": "E1aO7atTaTLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial=Trials()\n",
        "best = optimize(trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goX0NXxod1wS",
        "outputId": "bdd40baf-c13f-4e88-d640-9926c70eccea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6%|▋         | 13/200 [02:11<31:30, 10.11s/trial, best loss: 0.38179608221654265]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has improved our final result by a RMSE of 0.007. While this is nice, especially for only 2 min of tuning, it still makes for an impractical solution based on our design purpose, and the baseline random forest is better."
      ],
      "metadata": {
        "id": "ugI5GgCQwaEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK6AAL7CBxQp",
        "outputId": "e6d4f56a-1380-4eb5-b8d9-c176c66c9f4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 30, 'min_samples_split': 4, 'n_estimators': 250}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now I'll start the hypertuning process to see how much better we can make this\n",
        "grid_search = GridSearchCV(rnd_for_open, {'n_estimators': [100, 250, 500], 'max_depth':[2, 15, 30],\n",
        "    'min_samples_split':[2, 4, 6]}, cv=3, n_jobs = -1)\n",
        "grid_search.fit(x_train_open, y_train_open)\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8hY-TlXCGWs",
        "outputId": "4dc4581d-824a-44da-cfb0-63d49dac1367"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 70, 'min_samples_split': 3, 'n_estimators': 200}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search = GridSearchCV(rnd_for_open, {'n_estimators': [150, 200, 250, 300, 400, 450], 'max_depth':[30, 50, 70],\n",
        "    'min_samples_split':[3, 4, 5]}, cv=3, n_jobs = -1)\n",
        "grid_search.fit(x_train_open, y_train_open)\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE9bvSXCwusY",
        "outputId": "304dfd7e-d4ed-4737-a456-342b3e65d1e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 85, 'min_samples_split': 3, 'n_estimators': 160}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "grid_search = GridSearchCV(rnd_for_open, {'n_estimators': [160, 170, 180, 190, 200, 210, 220, 230, 240], 'max_depth':[70, 85, 100],\n",
        "    'min_samples_split':[3]}, cv=3, n_jobs = -1)\n",
        "grid_search.fit(x_train_open, y_train_open)\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6hi01Ts1BZN"
      },
      "source": [
        "### Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmSCBMBZ1Dmn",
        "outputId": "ae375adf-e1c0-4c59-ea1d-a4c5b32cb4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tuned model has a RMSE 0.001717540362127623 lower than the untuned model\n"
          ]
        }
      ],
      "source": [
        "rnd_for_open_ht = RandomForestRegressor(**grid_search.best_params_)\n",
        "rnd_for_open_ht.fit(x_train_open, y_train_open)\n",
        "\n",
        "pred_rf_open_ht = rnd_for_open_ht.predict(x_test_open)\n",
        "\n",
        "if np.sqrt(mean_squared_error(y_test_open, pred_rf_open_ht)) < np.sqrt(mean_squared_error(y_test_open, pred_rf_open)):\n",
        "  print('The tuned model has a RMSE', np.sqrt(mean_squared_error(y_test_open, pred_rf_open)) - np.sqrt(mean_squared_error(y_test_open, pred_rf_open_ht)), 'lower than the untuned model')\n",
        "else:\n",
        "  print('The tuned model has a worse RMSE than the untuned model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a similar scenario to the hyperopt tuning. While the gridsearched model does produce a better result by a RMSE of 0.002, it takes a total of >5min to run. This is non-satisfactory for a day trader who is trying to evaluate many stocks in a short period of time. Therefore we will build our prediciton model with the base random forest"
      ],
      "metadata": {
        "id": "9ZcSRRm0wzdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#storing the RMSE for later\n",
        "RMSE_open = np.sqrt(mean_squared_error(y_test_open, pred_rf_open))"
      ],
      "metadata": {
        "id": "5U9E1xNNkx_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating open predictions using baseline random forest\n",
        "tomorrows_open_pred_rf = rnd_for_open.predict(open_features)\n",
        "open_pred_rf = tomorrows_open_pred_rf[-1]"
      ],
      "metadata": {
        "id": "V8LyULQIc-JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGDeaFlv2pXn"
      },
      "source": [
        "## Close Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn9SSZNA_YAa",
        "outputId": "149c0c70-5afe-4d6f-bd9c-ff30584dd5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error is: 0.8902604311765772\n"
          ]
        }
      ],
      "source": [
        "rnd_for_close = RandomForestRegressor()\n",
        "rnd_for_close.fit(x_train_close, y_train_close)\n",
        "\n",
        "pred_rf_close = rnd_for_close.predict(x_test_close)\n",
        "\n",
        "print('Root mean squared error is:', np.sqrt(mean_squared_error(y_test_close, pred_rf_close)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWm2ul6wAQiR"
      },
      "source": [
        "### Hypertuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the hypertuning of the close model, I will transfer the learnings from above. This means that we will stick with the standard random forest model for deployment, mainly driven by the amount of run time hypertuning takes. However, I will include some gridsearching here just to satisfy my curiosity of how much it might improve the model"
      ],
      "metadata": {
        "id": "WsezfU1cxQE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPR5uqsBAQKx",
        "outputId": "1e9397e4-2fca-491b-af4f-0511226a276d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 250}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_close = GridSearchCV(rnd_for_close, {'max_depth':[20, 50, 75, 100],\n",
        "                                                 'min_samples_split':[2, 5, 10],\n",
        "                                                 'n_estimators':[100, 250, 500]}, cv=3, n_jobs=-1)\n",
        "grid_search_close.fit(x_train_close, y_train_close)\n",
        "grid_search_close.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N5p09yC8CiAE",
        "outputId": "604597bb-1855-4e5a-f550-56136ae8d3f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 10, 'min_samples_split': 4, 'n_estimators': 275}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_close = GridSearchCV(rnd_for_close, {'max_depth':[10, 15, 20],\n",
        "                                                 'min_samples_split':[3, 4, 5, 6, 7, 8, 9],\n",
        "                                                 'n_estimators':[125, 150, 175, 200, 225, 250, 275, 300,\n",
        "                                                                 325, 350, 375, 400, 425, 450, 475]}, cv=3, n_jobs=-1)\n",
        "grid_search_close.fit(x_train_close, y_train_close)\n",
        "grid_search_close.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_close = GridSearchCV(rnd_for_close, {'max_depth':[2, 4, 6, 8, 10],\n",
        "                                                 'min_samples_split':[4],\n",
        "                                                 'n_estimators':[260, 270, 275, 280, 290]}, cv=3, n_jobs=-1)\n",
        "grid_search_close.fit(x_train_close, y_train_close)\n",
        "grid_search_close.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irwnLct1glbv",
        "outputId": "27e69946-791e-48c0-fdbd-1cc23c7eb171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 275}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Model"
      ],
      "metadata": {
        "id": "LzwxHDYj9pPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_for_close_ht = RandomForestRegressor(**grid_search_close.best_params_)\n",
        "rnd_for_close_ht.fit(x_train_close, y_train_close)\n",
        "\n",
        "pred_rf_close_ht = rnd_for_close_ht.predict(x_test_close)\n",
        "\n",
        "if np.sqrt(mean_squared_error(y_test_close, pred_rf_close_ht)) < np.sqrt(mean_squared_error(y_test_close, pred_rf_close)):\n",
        "  print('The tuned model has a RMSE', np.sqrt(mean_squared_error(y_test_close, pred_rf_close)) - np.sqrt(mean_squared_error(y_test_close, pred_rf_close_ht)), 'lower than the untuned model')\n",
        "else:\n",
        "  print('The tuned model has a worse RMSE than the untuned model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNTEjgbp9ojl",
        "outputId": "78fa70ef-fc8d-4e42-e08f-b44e1562a908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tuned model has a worse RMSE than the untuned model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we actually see the tuned model performing worse than the original model. This is most likely a result of overfitting, but reinforces the idea that the amount of potential improvement in the model does not overrule the amount of run time tuning takes. If we were angling for the best possible model, we would want to take the time to tune it, but since we are angling for the best combination of RMSE and run time, tuning is not worth the cost."
      ],
      "metadata": {
        "id": "6UH5ZMf7xwp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#storing the RMSE for later\n",
        "RMSE_close = np.sqrt(mean_squared_error(y_test_close, pred_rf_close))"
      ],
      "metadata": {
        "id": "hOzuohjtlFok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tomorrows_close_pred_rf = rnd_for_close.predict(close_features)\n",
        "close_pred_rf = tomorrows_close_pred_rf[-1]"
      ],
      "metadata": {
        "id": "CNami7bjcsoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Signal"
      ],
      "metadata": {
        "id": "PiFGpYMa-RIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if close_pred_rf > open_pred_rf:\n",
        "  print('BUY: the stock is predicted to increase by', round(close_pred_rf - open_pred_rf, 3), 'tomorrow')\n",
        "  print('WARNING: this prediction could be off by as much as +/-', round(RMSE_open + RMSE_close, 3))\n",
        "else:\n",
        "  print('SELL: the stock is predicted to decrease by', round(close_pred_rf - open_pred_rf, 3), 'tomorrow')\n",
        "  print('WARNING: this prediction could be off by as much as +/-', round(RMSE_open + RMSE_close, 3))"
      ],
      "metadata": {
        "id": "Uxii_hAI-P42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe1e081-7d32-4ea3-859c-feefde7b9793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUY: the stock is predicted to increase by 0.033 tomorrow\n",
            "WARNING: this prediction could be off by as much as +/- 1.279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net Build"
      ],
      "metadata": {
        "id": "LgXFXEo3aklL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open Prediction"
      ],
      "metadata": {
        "id": "47CKeJ0hanrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Neural Net\n"
      ],
      "metadata": {
        "id": "P7V8xgOHasa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will start by building a basic deep neural network. This is similar in concept to what I did above with the random forest, and will provide a baseline for me to judge more tuned models against"
      ],
      "metadata": {
        "id": "6By_W7ExisTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_open_nn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3HGpQI3au3T",
        "outputId": "71fbbfe8-5ed5-456e-da9b-96fa1723e558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1485, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_model_deep = keras.models.Sequential([\n",
        "    keras.layers.Dense(1509, activation = 'relu'),\n",
        "    keras.layers.Dense(755, activation = 'relu'),\n",
        "    keras.layers.Dense(378, activation = 'relu'),\n",
        "    keras.layers.Dense(188, activation = 'relu'),\n",
        "    keras.layers.Dense(95, activation = 'relu'),\n",
        "    keras.layers.Dense(45, activation = 'relu'),\n",
        "    keras.layers.Dense(24, activation = 'relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "\n",
        "open_model_deep.compile(loss = 'huber',\n",
        "                        optimizer = optimizer,\n",
        "                        metrics=['mean_squared_error'])\n",
        "\n",
        "open_model_deep_1 = open_model_deep.fit(x_train_open_nn, y_train_open_nn, epochs=200,\n",
        "                             validation_data = (x_valid_open, y_valid_open),\n",
        "                              callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cOtARtWaxV1",
        "outputId": "7faa9d07-003b-4374-e3f9-281c17bcb01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 6s 48ms/step - loss: 20.0936 - mean_squared_error: 988.2274 - val_loss: 12.7823 - val_mean_squared_error: 301.9946\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 4.6298 - mean_squared_error: 48.2954 - val_loss: 2.9917 - val_mean_squared_error: 20.6872\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 1.8841 - mean_squared_error: 11.6684 - val_loss: 1.4091 - val_mean_squared_error: 5.9303\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 1.2658 - mean_squared_error: 5.2582 - val_loss: 1.6340 - val_mean_squared_error: 6.8887\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 1.2778 - mean_squared_error: 5.1191 - val_loss: 1.4783 - val_mean_squared_error: 6.6864\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 3s 54ms/step - loss: 0.8390 - mean_squared_error: 2.8613 - val_loss: 0.8481 - val_mean_squared_error: 2.9887\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 1.4064 - mean_squared_error: 6.5252 - val_loss: 0.9700 - val_mean_squared_error: 3.5913\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 3s 56ms/step - loss: 1.5476 - mean_squared_error: 7.7060 - val_loss: 0.5000 - val_mean_squared_error: 1.5881\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 1.3955 - mean_squared_error: 5.7934 - val_loss: 0.9404 - val_mean_squared_error: 3.7492\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 2.3156 - mean_squared_error: 12.8029 - val_loss: 1.3683 - val_mean_squared_error: 4.6914\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.7945 - mean_squared_error: 2.9101 - val_loss: 0.4616 - val_mean_squared_error: 1.2602\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 1.1349 - mean_squared_error: 4.3991 - val_loss: 0.8989 - val_mean_squared_error: 3.3152\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.7277 - mean_squared_error: 2.3667 - val_loss: 0.6526 - val_mean_squared_error: 2.1231\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 2.0704 - mean_squared_error: 10.4624 - val_loss: 0.8353 - val_mean_squared_error: 3.0308\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.8514 - mean_squared_error: 3.2627 - val_loss: 1.1003 - val_mean_squared_error: 4.5839\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 2s 51ms/step - loss: 0.6537 - mean_squared_error: 1.9944 - val_loss: 1.4319 - val_mean_squared_error: 5.3145\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 0.7594 - mean_squared_error: 2.5374 - val_loss: 0.4619 - val_mean_squared_error: 1.0982\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 1s 32ms/step - loss: 0.5838 - mean_squared_error: 1.7609 - val_loss: 0.7029 - val_mean_squared_error: 2.2211\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 1.1687 - mean_squared_error: 4.3197 - val_loss: 0.7282 - val_mean_squared_error: 2.4686\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.6037 - mean_squared_error: 1.7741 - val_loss: 1.1108 - val_mean_squared_error: 4.4960\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.7191 - mean_squared_error: 2.3092 - val_loss: 1.0121 - val_mean_squared_error: 3.3997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep and Wide NN"
      ],
      "metadata": {
        "id": "1713PVORbMT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.layers.Input(shape = x_train_open_nn.shape[1:])\n",
        "hidden1 = keras.layers.Dense(1509, activation = 'relu')(input)\n",
        "hidden2 = keras.layers.Dense(755, activation = 'relu')(hidden1)\n",
        "hidden3 = keras.layers.Dense(378, activation = 'relu')(hidden2)\n",
        "hidden4 = keras.layers.Dense(188, activation = 'relu')(hidden3)\n",
        "hidden5 = keras.layers.Dense(95, activation = 'relu')(hidden4)\n",
        "hidden6 = keras.layers.Dense(45, activation = 'relu')(hidden5)\n",
        "hidden7 = keras.layers.Dense(24, activation = 'relu')(hidden6)\n",
        "concat = keras.layers.concatenate([input, hidden7])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "open_model_deep_wide = keras.models.Model(inputs=[input], outputs = [output])\n",
        "\n",
        "open_model_deep_wide.compile(loss = 'huber',\n",
        "                             optimizer = 'adam',\n",
        "                             metrics=['mean_squared_error'])\n",
        "\n",
        "open_model_deep_wide_1 = open_model_deep_wide.fit(x_train_open_nn, y_train_open_nn, epochs=200,\n",
        "                             validation_data = (x_valid_open, y_valid_open),\n",
        "                         callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4YxUS6XbJuM",
        "outputId": "d55080b6-16cf-476c-fd6c-bf9e3fee21eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 4s 47ms/step - loss: 13.6112 - mean_squared_error: 385.2076 - val_loss: 5.8571 - val_mean_squared_error: 71.9141\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 2s 50ms/step - loss: 3.1653 - mean_squared_error: 39.1800 - val_loss: 3.1694 - val_mean_squared_error: 22.2515\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 1.6537 - mean_squared_error: 14.7034 - val_loss: 2.6673 - val_mean_squared_error: 18.5659\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.3487 - mean_squared_error: 8.5466 - val_loss: 1.4945 - val_mean_squared_error: 7.6577\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 3s 52ms/step - loss: 0.7612 - mean_squared_error: 3.3581 - val_loss: 1.2762 - val_mean_squared_error: 5.2862\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.4433 - mean_squared_error: 1.2827 - val_loss: 1.1062 - val_mean_squared_error: 4.7959\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.6297 - mean_squared_error: 1.9653 - val_loss: 1.3880 - val_mean_squared_error: 6.0727\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 2s 53ms/step - loss: 0.5990 - mean_squared_error: 1.8698 - val_loss: 0.8124 - val_mean_squared_error: 3.0980\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 0.4585 - mean_squared_error: 1.2180 - val_loss: 0.9422 - val_mean_squared_error: 3.9902\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.6075 - mean_squared_error: 1.6750 - val_loss: 0.9318 - val_mean_squared_error: 4.0337\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.4208 - mean_squared_error: 1.1722 - val_loss: 1.0730 - val_mean_squared_error: 3.8753\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.3909 - mean_squared_error: 1.0795 - val_loss: 0.8248 - val_mean_squared_error: 3.9424\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.4531 - mean_squared_error: 1.1376 - val_loss: 0.6755 - val_mean_squared_error: 2.7740\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.6118 - mean_squared_error: 1.8394 - val_loss: 0.6015 - val_mean_squared_error: 2.2482\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.4035 - mean_squared_error: 1.0615 - val_loss: 0.6703 - val_mean_squared_error: 3.2750\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 3s 54ms/step - loss: 0.2724 - mean_squared_error: 0.6634 - val_loss: 0.4436 - val_mean_squared_error: 1.5797\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.3162 - mean_squared_error: 0.8427 - val_loss: 0.8242 - val_mean_squared_error: 3.6332\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.4210 - mean_squared_error: 1.0610 - val_loss: 0.6200 - val_mean_squared_error: 2.4936\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.4039 - mean_squared_error: 1.0366 - val_loss: 0.7959 - val_mean_squared_error: 3.1580\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.3330 - mean_squared_error: 0.8320 - val_loss: 0.6938 - val_mean_squared_error: 2.5277\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.3470 - mean_squared_error: 0.8501 - val_loss: 0.7859 - val_mean_squared_error: 3.4346\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.2242 - mean_squared_error: 0.5393 - val_loss: 0.5650 - val_mean_squared_error: 2.2022\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 0.3909 - mean_squared_error: 1.0050 - val_loss: 1.0094 - val_mean_squared_error: 3.5256\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 0.3497 - mean_squared_error: 0.8781 - val_loss: 1.1443 - val_mean_squared_error: 4.6132\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.3575 - mean_squared_error: 0.9624 - val_loss: 0.8984 - val_mean_squared_error: 3.7676\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.3569 - mean_squared_error: 0.8735 - val_loss: 0.7069 - val_mean_squared_error: 2.4576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Model with Normalization\n"
      ],
      "metadata": {
        "id": "EqYWh--Rv6hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "open_model_deep_normalized = keras.models.Sequential([\n",
        "    keras.layers.Dense(1509, activation = 'relu'),\n",
        "    keras.layers.Dense(755, activation = 'relu'),\n",
        "    keras.layers.Dense(378, activation = 'relu'),\n",
        "    keras.layers.Dense(188, activation = 'relu'),\n",
        "    keras.layers.Dense(95, activation = 'relu'),\n",
        "    keras.layers.Dense(45, activation = 'relu'),\n",
        "    keras.layers.Dense(24, activation = 'relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.01)\n",
        "\n",
        "open_model_deep_normalized.compile(loss = 'huber',\n",
        "                                   optimizer = optimizer,\n",
        "                                   metrics=['mean_squared_error'])\n",
        "\n",
        "open_model_deep_norm = open_model_deep_normalized.fit(x_train_open_nn, y_train_open_nn, epochs=200,\n",
        "                                                            validation_data = (x_valid_open, y_valid_open),\n",
        "                                                            callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KebTKzKDrptY",
        "outputId": "4f3c9dcd-1e11-441b-e208-33e8f3014bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 4s 40ms/step - loss: 31.7014 - mean_squared_error: 1182.3743 - val_loss: 24.5154 - val_mean_squared_error: 744.4561\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 12.6719 - mean_squared_error: 286.4870 - val_loss: 25.8416 - val_mean_squared_error: 1132.6729\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 2.2793 - mean_squared_error: 17.5634 - val_loss: 14.8270 - val_mean_squared_error: 302.3148\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.6313 - mean_squared_error: 7.4372 - val_loss: 10.3043 - val_mean_squared_error: 145.2472\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 1.7607 - mean_squared_error: 9.6375 - val_loss: 26.9365 - val_mean_squared_error: 1011.9556\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.7437 - mean_squared_error: 8.4522 - val_loss: 7.5168 - val_mean_squared_error: 78.5022\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.2692 - mean_squared_error: 5.7533 - val_loss: 6.2312 - val_mean_squared_error: 52.1577\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.5836 - mean_squared_error: 6.5035 - val_loss: 4.8606 - val_mean_squared_error: 33.1604\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.2386 - mean_squared_error: 5.0056 - val_loss: 1.3875 - val_mean_squared_error: 4.3012\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5275 - mean_squared_error: 7.2350 - val_loss: 1.3557 - val_mean_squared_error: 4.5362\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.8650 - mean_squared_error: 9.5171 - val_loss: 2.7525 - val_mean_squared_error: 12.8587\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.4285 - mean_squared_error: 6.2252 - val_loss: 2.1466 - val_mean_squared_error: 8.8066\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 1s 29ms/step - loss: 1.4877 - mean_squared_error: 6.6311 - val_loss: 1.7836 - val_mean_squared_error: 13.5234\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.6676 - mean_squared_error: 8.1098 - val_loss: 0.8596 - val_mean_squared_error: 2.4156\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 1.4577 - mean_squared_error: 6.4784 - val_loss: 1.3866 - val_mean_squared_error: 4.5751\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.3987 - mean_squared_error: 5.7784 - val_loss: 0.8908 - val_mean_squared_error: 2.5943\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.4043 - mean_squared_error: 6.5937 - val_loss: 0.7084 - val_mean_squared_error: 1.9491\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.5682 - mean_squared_error: 7.3285 - val_loss: 0.5840 - val_mean_squared_error: 1.5706\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.3402 - mean_squared_error: 5.8051 - val_loss: 1.0813 - val_mean_squared_error: 3.0279\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.7344 - mean_squared_error: 8.7205 - val_loss: 0.8710 - val_mean_squared_error: 2.4203\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.6703 - mean_squared_error: 7.3495 - val_loss: 0.9238 - val_mean_squared_error: 2.2437\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.3707 - mean_squared_error: 6.4091 - val_loss: 0.3502 - val_mean_squared_error: 0.9701\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 1.5789 - mean_squared_error: 7.6055 - val_loss: 0.7475 - val_mean_squared_error: 2.0450\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.4624 - mean_squared_error: 6.0229 - val_loss: 1.0257 - val_mean_squared_error: 3.3121\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 1.5101 - mean_squared_error: 6.4166 - val_loss: 0.3196 - val_mean_squared_error: 0.7347\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5313 - mean_squared_error: 7.3623 - val_loss: 0.3724 - val_mean_squared_error: 0.8539\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.5466 - mean_squared_error: 7.9423 - val_loss: 0.6475 - val_mean_squared_error: 1.4226\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.5440 - mean_squared_error: 7.2946 - val_loss: 0.8803 - val_mean_squared_error: 2.4944\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5237 - mean_squared_error: 6.2195 - val_loss: 1.0266 - val_mean_squared_error: 2.5753\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.4488 - mean_squared_error: 6.3872 - val_loss: 0.7985 - val_mean_squared_error: 2.3583\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.4177 - mean_squared_error: 6.1444 - val_loss: 0.2997 - val_mean_squared_error: 0.6908\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.2287 - mean_squared_error: 5.1247 - val_loss: 0.4355 - val_mean_squared_error: 1.1270\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 1s 32ms/step - loss: 1.4128 - mean_squared_error: 6.3537 - val_loss: 0.9385 - val_mean_squared_error: 2.3352\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 1.4659 - mean_squared_error: 6.4744 - val_loss: 0.7450 - val_mean_squared_error: 1.7825\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 1s 28ms/step - loss: 1.5534 - mean_squared_error: 7.3716 - val_loss: 0.8583 - val_mean_squared_error: 2.5248\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.2664 - mean_squared_error: 5.6890 - val_loss: 0.5676 - val_mean_squared_error: 1.6734\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.3757 - mean_squared_error: 6.0961 - val_loss: 0.5509 - val_mean_squared_error: 1.5134\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5964 - mean_squared_error: 7.6308 - val_loss: 1.0047 - val_mean_squared_error: 2.8749\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.4171 - mean_squared_error: 6.4112 - val_loss: 0.2484 - val_mean_squared_error: 0.5619\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5745 - mean_squared_error: 8.4514 - val_loss: 0.2625 - val_mean_squared_error: 0.5800\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.6161 - mean_squared_error: 7.5817 - val_loss: 1.2116 - val_mean_squared_error: 4.2509\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.2956 - mean_squared_error: 5.9558 - val_loss: 1.0903 - val_mean_squared_error: 4.9211\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.4439 - mean_squared_error: 6.9078 - val_loss: 0.6489 - val_mean_squared_error: 1.8611\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 2s 39ms/step - loss: 1.6031 - mean_squared_error: 7.9141 - val_loss: 0.1404 - val_mean_squared_error: 0.3153\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.3121 - mean_squared_error: 6.4299 - val_loss: 0.8519 - val_mean_squared_error: 3.3221\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.6249 - mean_squared_error: 7.9320 - val_loss: 0.7807 - val_mean_squared_error: 2.3544\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.8154 - mean_squared_error: 8.6901 - val_loss: 0.5980 - val_mean_squared_error: 2.3958\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.3935 - mean_squared_error: 6.1256 - val_loss: 0.5656 - val_mean_squared_error: 2.0409\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.4294 - mean_squared_error: 6.8548 - val_loss: 0.1830 - val_mean_squared_error: 0.4037\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.4898 - mean_squared_error: 6.4041 - val_loss: 0.3720 - val_mean_squared_error: 0.8143\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 1s 28ms/step - loss: 1.2701 - mean_squared_error: 5.6417 - val_loss: 1.3414 - val_mean_squared_error: 3.6710\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 1.4523 - mean_squared_error: 6.4985 - val_loss: 1.0934 - val_mean_squared_error: 2.9833\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.5713 - mean_squared_error: 8.1692 - val_loss: 0.7417 - val_mean_squared_error: 1.7482\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 1.5927 - mean_squared_error: 7.4350 - val_loss: 0.2705 - val_mean_squared_error: 0.6462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison"
      ],
      "metadata": {
        "id": "kwwfPwBNbZZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Model\n",
        "deep_error = open_model_deep.evaluate(scaled_x_test_open, y_test_open)\n",
        "np.sqrt(deep_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lMxK4CbauP",
        "outputId": "9403ff75-1362-4e9a-c960-9e3fb1028c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7273 - mean_squared_error: 2.0763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85279222, 1.44092872])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7ms/step and a RMSE of 1.44"
      ],
      "metadata": {
        "id": "3QubFcknwYkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functional Model\n",
        "deep_wide_error = open_model_deep_wide.evaluate(scaled_x_test_open, y_test_open)\n",
        "np.sqrt(deep_wide_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruv3L8HEbdfP",
        "outputId": "e4d558f7-cda8-415d-9099-5db9d0fee66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4852 - mean_squared_error: 1.2010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.69655402, 1.09588246])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10ms/step and a RMSE of 1.10. Slower than the deep model but 0.34 better RMSE"
      ],
      "metadata": {
        "id": "pj1Qd14lwcm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalized Base\n",
        "deep_norm_error = open_model_deep_normalized.evaluate(scaled_x_test_open, y_test_open)\n",
        "rmse_open_nn = np.sqrt(deep_norm_error)\n",
        "rmse_open_nn = rmse_open_nn[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G5pWtKTs0z1",
        "outputId": "18385312-c922-469b-c23b-8d92890bf654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2745 - mean_squared_error: 0.8408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ms/step and 0.92 RMSE. Fastest and lowest RMSE"
      ],
      "metadata": {
        "id": "_qBMyH0ywiz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoever, this is still higher than the RMSE from the open model of the random forest. So, for the open predicition, random forest is optimal"
      ],
      "metadata": {
        "id": "C1HqoE5KnqiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "7T00ZeSVbjsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tomorrows_open_pred_nn = open_model_deep_normalized.predict(scaled_open_features)\n",
        "open_pred_nn = tomorrows_open_pred_nn[-1]"
      ],
      "metadata": {
        "id": "fJ6Z-fT7bktM",
        "outputId": "ca2982ab-de0d-4ba8-a2f0-90360f0d69ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/78 [==============================] - 1s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Close Predicition"
      ],
      "metadata": {
        "id": "TSLM_odcZ8nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of this will follow the same logic and steps as above"
      ],
      "metadata": {
        "id": "TbNfeRuNmI5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Neural Net"
      ],
      "metadata": {
        "id": "SnMq-Wj8Z_gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_close_nn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkbvWqYvZ-PX",
        "outputId": "fa8fb0a3-1a84-44c9-8185-31d949df0c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1485, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "close_model_deep = keras.models.Sequential([\n",
        "    keras.layers.Dense(1509, activation = 'relu'),\n",
        "    keras.layers.Dense(755, activation = 'relu'),\n",
        "    keras.layers.Dense(378, activation = 'relu'),\n",
        "    keras.layers.Dense(188, activation = 'relu'),\n",
        "    keras.layers.Dense(95, activation = 'relu'),\n",
        "    keras.layers.Dense(45, activation = 'relu'),\n",
        "    keras.layers.Dense(24, activation = 'relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "\n",
        "close_model_deep.compile(loss = 'huber',\n",
        "                         optimizer = optimizer,\n",
        "                         metrics=['mean_squared_error'])\n",
        "\n",
        "close_model_deep_1 = close_model_deep.fit(x_train_close_nn, y_train_close_nn, epochs=200,\n",
        "                                          validation_data = (x_valid_close, y_valid_close),\n",
        "                                          callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YzmIzYHaEau",
        "outputId": "61dd26ab-fd53-488e-cff6-b265446d5a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 4s 55ms/step - loss: 20.2030 - mean_squared_error: 1486.9266 - val_loss: 6.1370 - val_mean_squared_error: 76.1761\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 3.9125 - mean_squared_error: 34.8964 - val_loss: 2.8009 - val_mean_squared_error: 21.4268\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 3.7004 - mean_squared_error: 36.0983 - val_loss: 7.1998 - val_mean_squared_error: 75.7311\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 1s 32ms/step - loss: 2.3333 - mean_squared_error: 17.7226 - val_loss: 1.9045 - val_mean_squared_error: 10.8275\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 1s 31ms/step - loss: 1.7803 - mean_squared_error: 8.9186 - val_loss: 3.7448 - val_mean_squared_error: 29.8602\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 1s 31ms/step - loss: 1.5261 - mean_squared_error: 7.3205 - val_loss: 1.1263 - val_mean_squared_error: 4.4104\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 1.1123 - mean_squared_error: 4.7311 - val_loss: 2.6031 - val_mean_squared_error: 13.1833\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 1.7966 - mean_squared_error: 8.2918 - val_loss: 2.0491 - val_mean_squared_error: 11.6709\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 1.3248 - mean_squared_error: 6.1714 - val_loss: 1.1248 - val_mean_squared_error: 4.0586\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 1.2399 - mean_squared_error: 5.1698 - val_loss: 0.9942 - val_mean_squared_error: 3.2466\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.9754 - mean_squared_error: 3.7372 - val_loss: 0.8012 - val_mean_squared_error: 2.9929\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.9007 - mean_squared_error: 3.3351 - val_loss: 2.6885 - val_mean_squared_error: 12.5255\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 0.9553 - mean_squared_error: 3.3365 - val_loss: 0.8197 - val_mean_squared_error: 2.9156\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 1s 31ms/step - loss: 1.0740 - mean_squared_error: 4.4525 - val_loss: 4.0216 - val_mean_squared_error: 22.5316\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 1.3959 - mean_squared_error: 6.9854 - val_loss: 0.9088 - val_mean_squared_error: 3.0885\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.8036 - mean_squared_error: 2.7038 - val_loss: 1.0091 - val_mean_squared_error: 3.2813\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 2s 51ms/step - loss: 0.6766 - mean_squared_error: 2.1703 - val_loss: 0.9725 - val_mean_squared_error: 2.8752\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 2s 38ms/step - loss: 0.7745 - mean_squared_error: 2.4146 - val_loss: 2.4144 - val_mean_squared_error: 11.4811\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 1.1782 - mean_squared_error: 4.3395 - val_loss: 0.9926 - val_mean_squared_error: 3.9396\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 1.5439 - mean_squared_error: 7.4647 - val_loss: 1.6458 - val_mean_squared_error: 8.3724\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 1.0791 - mean_squared_error: 4.0892 - val_loss: 0.9584 - val_mean_squared_error: 3.0769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep and Wide NN"
      ],
      "metadata": {
        "id": "2jJrpO0ibNZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.layers.Input(shape = x_train_close_nn.shape[1:])\n",
        "hidden1 = keras.layers.Dense(1509, activation = 'relu')(input)\n",
        "hidden2 = keras.layers.Dense(755, activation = 'relu')(hidden1)\n",
        "hidden3 = keras.layers.Dense(378, activation = 'relu')(hidden2)\n",
        "hidden4 = keras.layers.Dense(188, activation = 'relu')(hidden3)\n",
        "hidden5 = keras.layers.Dense(95, activation = 'relu')(hidden4)\n",
        "hidden6 = keras.layers.Dense(45, activation = 'relu')(hidden5)\n",
        "hidden7 = keras.layers.Dense(24, activation = 'relu')(hidden6)\n",
        "concat = keras.layers.concatenate([input, hidden7])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "close_model_deep_wide = keras.models.Model(inputs=[input], outputs = [output])\n",
        "\n",
        "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.01)\n",
        "\n",
        "close_model_deep_wide.compile(loss = 'huber',\n",
        "                              optimizer = optimizer,\n",
        "                              metrics=['mean_squared_error'])\n",
        "\n",
        "close_model_deep_wide_1 = close_model_deep_wide.fit(x_train_close_nn, y_train_close_nn, epochs=200,\n",
        "                                                    validation_data = (x_valid_open, y_valid_open),\n",
        "                                                    callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22wMS8AWbO-7",
        "outputId": "31d47fbe-f438-4d61-a09e-f70378966caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 4s 42ms/step - loss: 18.6079 - mean_squared_error: 1395.8914 - val_loss: 9.0887 - val_mean_squared_error: 125.1594\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 3.4240 - mean_squared_error: 33.5174 - val_loss: 3.0758 - val_mean_squared_error: 24.4044\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 1s 30ms/step - loss: 3.3928 - mean_squared_error: 26.6521 - val_loss: 1.0601 - val_mean_squared_error: 4.2642\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 1.6228 - mean_squared_error: 7.5401 - val_loss: 1.8659 - val_mean_squared_error: 10.4472\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 1.8022 - mean_squared_error: 8.9306 - val_loss: 1.3273 - val_mean_squared_error: 6.5517\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 2s 34ms/step - loss: 1.6882 - mean_squared_error: 8.5179 - val_loss: 1.5874 - val_mean_squared_error: 6.3917\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 1.6091 - mean_squared_error: 7.3656 - val_loss: 1.4752 - val_mean_squared_error: 6.0903\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.0257 - mean_squared_error: 4.8916 - val_loss: 1.8451 - val_mean_squared_error: 10.7806\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 2s 32ms/step - loss: 2.1309 - mean_squared_error: 10.5693 - val_loss: 0.7700 - val_mean_squared_error: 2.6330\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 0.9857 - mean_squared_error: 3.6028 - val_loss: 0.8643 - val_mean_squared_error: 2.8536\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 0.6427 - mean_squared_error: 2.0089 - val_loss: 0.9183 - val_mean_squared_error: 3.2603\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 0.7950 - mean_squared_error: 2.6148 - val_loss: 0.4669 - val_mean_squared_error: 1.2908\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 3s 72ms/step - loss: 1.0441 - mean_squared_error: 3.9617 - val_loss: 0.6200 - val_mean_squared_error: 1.7397\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 0.7107 - mean_squared_error: 2.2042 - val_loss: 0.5367 - val_mean_squared_error: 1.3978\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 0.5948 - mean_squared_error: 1.8027 - val_loss: 1.5219 - val_mean_squared_error: 4.7941\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 2s 48ms/step - loss: 0.9826 - mean_squared_error: 3.3401 - val_loss: 0.7528 - val_mean_squared_error: 2.5331\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 0.5357 - mean_squared_error: 1.5820 - val_loss: 0.9343 - val_mean_squared_error: 3.2851\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 0.6546 - mean_squared_error: 1.9158 - val_loss: 0.3050 - val_mean_squared_error: 0.7765\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 0.5299 - mean_squared_error: 1.5693 - val_loss: 0.4586 - val_mean_squared_error: 1.1683\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.6982 - mean_squared_error: 2.1974 - val_loss: 0.5870 - val_mean_squared_error: 1.5494\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.7108 - mean_squared_error: 2.2778 - val_loss: 0.6516 - val_mean_squared_error: 1.5409\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 1s 24ms/step - loss: 0.9706 - mean_squared_error: 3.2159 - val_loss: 0.4491 - val_mean_squared_error: 1.0744\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.4087 - mean_squared_error: 1.1680 - val_loss: 0.6427 - val_mean_squared_error: 1.8050\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.5420 - mean_squared_error: 1.6050 - val_loss: 0.4083 - val_mean_squared_error: 1.2007\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.6126 - mean_squared_error: 1.8968 - val_loss: 0.2764 - val_mean_squared_error: 0.6646\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 1s 24ms/step - loss: 0.6493 - mean_squared_error: 2.1263 - val_loss: 0.8880 - val_mean_squared_error: 2.5180\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.5277 - mean_squared_error: 1.5533 - val_loss: 0.4648 - val_mean_squared_error: 1.0958\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 0.5858 - mean_squared_error: 1.7098 - val_loss: 0.3307 - val_mean_squared_error: 0.8625\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 0.4766 - mean_squared_error: 1.3552 - val_loss: 2.4799 - val_mean_squared_error: 9.5559\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.7249 - mean_squared_error: 2.3463 - val_loss: 0.6273 - val_mean_squared_error: 1.5433\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.6154 - mean_squared_error: 1.8690 - val_loss: 1.1033 - val_mean_squared_error: 3.5152\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.7319 - mean_squared_error: 2.1689 - val_loss: 0.2251 - val_mean_squared_error: 0.5157\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 0.3515 - mean_squared_error: 1.0169 - val_loss: 0.4804 - val_mean_squared_error: 1.3702\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.3446 - mean_squared_error: 1.0131 - val_loss: 0.3143 - val_mean_squared_error: 0.7316\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 0.3988 - mean_squared_error: 1.1100 - val_loss: 0.3110 - val_mean_squared_error: 0.7763\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.3470 - mean_squared_error: 1.0694 - val_loss: 0.2822 - val_mean_squared_error: 0.6811\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.3160 - mean_squared_error: 0.8870 - val_loss: 0.5732 - val_mean_squared_error: 1.4574\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 2s 38ms/step - loss: 0.4260 - mean_squared_error: 1.2099 - val_loss: 0.2776 - val_mean_squared_error: 0.6695\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.3383 - mean_squared_error: 0.9721 - val_loss: 0.3748 - val_mean_squared_error: 0.9392\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.2951 - mean_squared_error: 0.8686 - val_loss: 0.2616 - val_mean_squared_error: 0.6393\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 0.4208 - mean_squared_error: 1.1715 - val_loss: 0.3935 - val_mean_squared_error: 1.0555\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 0.3913 - mean_squared_error: 1.1088 - val_loss: 0.2603 - val_mean_squared_error: 0.6319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep with Normalization"
      ],
      "metadata": {
        "id": "RTSEnAmWw4vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "close_model_deep_normalized = keras.models.Sequential([\n",
        "    keras.layers.Dense(1509, activation = 'relu'),\n",
        "    keras.layers.Dense(755, activation = 'relu'),\n",
        "    keras.layers.Dense(378, activation = 'relu'),\n",
        "    keras.layers.Dense(188, activation = 'relu'),\n",
        "    keras.layers.Dense(95, activation = 'relu'),\n",
        "    keras.layers.Dense(45, activation = 'relu'),\n",
        "    keras.layers.Dense(24, activation = 'relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
        "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.01)\n",
        "\n",
        "close_model_deep_normalized.compile(loss = 'huber',\n",
        "                                    optimizer = optimizer,\n",
        "                                    metrics=['mean_squared_error'])\n",
        "\n",
        "close_model_deep_2 = close_model_deep_normalized.fit(x_train_close_nn, y_train_close_nn, epochs=200,\n",
        "                                                     validation_data = (x_valid_close, y_valid_close),\n",
        "                                                     callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqeyhogaw7sV",
        "outputId": "7998d37d-73e8-4e14-cf59-b34ad6228a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 3s 34ms/step - loss: 31.8864 - mean_squared_error: 1187.5305 - val_loss: 25.7355 - val_mean_squared_error: 809.5445\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 13.0769 - mean_squared_error: 333.4823 - val_loss: 42.0852 - val_mean_squared_error: 2548.4941\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 2s 35ms/step - loss: 2.6943 - mean_squared_error: 20.1753 - val_loss: 27.2900 - val_mean_squared_error: 829.3704\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.9504 - mean_squared_error: 10.7434 - val_loss: 13.5281 - val_mean_squared_error: 214.1423\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.9394 - mean_squared_error: 9.8444 - val_loss: 8.4680 - val_mean_squared_error: 85.2448\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 3.5142 - mean_squared_error: 30.5415 - val_loss: 21.5022 - val_mean_squared_error: 1078.7816\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 3.0425 - mean_squared_error: 22.6780 - val_loss: 38.3872 - val_mean_squared_error: 2124.6538\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.8310 - mean_squared_error: 9.1506 - val_loss: 22.1573 - val_mean_squared_error: 573.1840\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.7900 - mean_squared_error: 9.4019 - val_loss: 10.7485 - val_mean_squared_error: 132.9753\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.6402 - mean_squared_error: 7.8212 - val_loss: 10.6959 - val_mean_squared_error: 128.1288\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 2s 33ms/step - loss: 1.5810 - mean_squared_error: 7.9821 - val_loss: 6.4454 - val_mean_squared_error: 54.4152\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 1.7343 - mean_squared_error: 8.8141 - val_loss: 4.4509 - val_mean_squared_error: 30.1881\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5806 - mean_squared_error: 7.2010 - val_loss: 1.8297 - val_mean_squared_error: 7.9662\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.4894 - mean_squared_error: 7.0594 - val_loss: 0.9995 - val_mean_squared_error: 3.2140\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 1.3904 - mean_squared_error: 6.0091 - val_loss: 1.4676 - val_mean_squared_error: 5.3852\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 1s 24ms/step - loss: 1.5867 - mean_squared_error: 7.6022 - val_loss: 1.5918 - val_mean_squared_error: 5.9819\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.4806 - mean_squared_error: 7.4856 - val_loss: 1.2568 - val_mean_squared_error: 4.2570\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.8492 - mean_squared_error: 9.3087 - val_loss: 1.7563 - val_mean_squared_error: 6.0450\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.7185 - mean_squared_error: 8.8838 - val_loss: 0.9480 - val_mean_squared_error: 2.8275\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.8135 - mean_squared_error: 9.4351 - val_loss: 0.4027 - val_mean_squared_error: 0.9968\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 2s 36ms/step - loss: 1.4585 - mean_squared_error: 6.4603 - val_loss: 1.5187 - val_mean_squared_error: 5.2120\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 2s 41ms/step - loss: 1.7910 - mean_squared_error: 9.8430 - val_loss: 0.9552 - val_mean_squared_error: 2.7926\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.4907 - mean_squared_error: 7.4845 - val_loss: 1.0406 - val_mean_squared_error: 4.5817\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.8036 - mean_squared_error: 10.2573 - val_loss: 0.4259 - val_mean_squared_error: 1.0370\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 3.3605 - mean_squared_error: 36.1525 - val_loss: 9.3574 - val_mean_squared_error: 169.9248\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 1.5423 - mean_squared_error: 7.1650 - val_loss: 3.7210 - val_mean_squared_error: 23.8323\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.5012 - mean_squared_error: 6.8726 - val_loss: 2.9846 - val_mean_squared_error: 15.4456\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 2.0036 - mean_squared_error: 10.1277 - val_loss: 1.6178 - val_mean_squared_error: 5.8722\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.7741 - mean_squared_error: 8.7668 - val_loss: 1.3654 - val_mean_squared_error: 4.0603\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 1.4687 - mean_squared_error: 6.3121 - val_loss: 0.6688 - val_mean_squared_error: 1.7588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison"
      ],
      "metadata": {
        "id": "Ui0fjzeWbucT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Model\n",
        "close_error_deep = close_model_deep.evaluate(scaled_x_test_close, y_test_close)\n",
        "np.sqrt(close_error_deep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeW_iHozbvUM",
        "outputId": "f20cf438-1aa4-4a1e-c5ba-78130b7887ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6976 - mean_squared_error: 2.5134\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8352383 , 1.58535967])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7ms/step and RMSE of 1.59 as baseline"
      ],
      "metadata": {
        "id": "pmmBLGac0jTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functional Model\n",
        "close_error_deep_wide = close_model_deep_wide.evaluate(scaled_x_test_close, y_test_close)\n",
        "rmse_close_nn = np.sqrt(close_error_deep_wide)\n",
        "rmse_close_nn = rmse_close_nn[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z15Dpgv-cERu",
        "outputId": "ebd1e1f1-df0d-460d-923a-2b914d6a1385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3614 - mean_squared_error: 0.9100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ms/step and RMSE of 0.95. Slightly faster and much better RMSE"
      ],
      "metadata": {
        "id": "FmTSw_wK0nLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "close_error_deep_norm = close_model_deep_normalized.evaluate(scaled_x_test_close, y_test_close)\n",
        "np.sqrt(close_error_deep_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urGSwsjxg1Y",
        "outputId": "22eeb0c3-3d95-4176-fa29-658479d194b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3587 - mean_squared_error: 0.9316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5988882 , 0.96517463])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ms/step and RMSE of 0.97. Slightly worse RMSE than deep wide"
      ],
      "metadata": {
        "id": "kA684t090y2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep wide is the best, but again it has a higher RMSE than random forest and longer run time, so random forest is optimal for close as well"
      ],
      "metadata": {
        "id": "NJyCn0tao9Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicition"
      ],
      "metadata": {
        "id": "kKK77iB5cJ6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tomorrows_close_pred_nn = close_model_deep_normalized.predict(scaled_close_features)\n",
        "close_pred_nn = tomorrows_close_pred_nn[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXxn_-OBcK8T",
        "outputId": "a060e319-c898-4c99-917f-7f7db853b55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/78 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net Signal"
      ],
      "metadata": {
        "id": "XNbzbDQ-faCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if close_pred_nn > open_pred_nn:\n",
        "  print('BUY, the stock is predicted to increase by', close_pred_nn - open_pred_nn, 'tomorrow')\n",
        "  print('WARNING: this prediction could be off by as much as +/-', round(rmse_open_nn + rmse_close_nn, 3))\n",
        "else:\n",
        "  print('SELL, the stock is predicted to decrease by', close_pred_nn - open_pred_nn, 'tomorrow')\n",
        "  print('WARNING: this prediction could be off by as much as +/-', round(rmse_open_nn + rmse_close_nn, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDYo_Mg9fZwS",
        "outputId": "5f512a22-d48e-46bd-99d7-496a527d9c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELL, the stock is predicted to decrease by [-0.53027344] tomorrow\n",
            "WARNING: this prediction could be off by as much as +/- 1.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "0oP9qx3F-FrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What I have found is that the random forest model generally performs better on stock data than the neural network does. This is a surprising finding for me, I initially assumed that the neural network would perform better since it is a more robust approach.\n",
        "\n",
        "The final deployed app can be found at daytradingstocksignalsystem.streamlit.app\n",
        "\n",
        "Next steps on this project could include a more robust handling of volatility, potentially involving the use of GARCH instead of standard deviation, and further research to find a pre-trained neural net that could be used for a better initialization"
      ],
      "metadata": {
        "id": "ca3ZRkOS-HhF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d503Sc00KiNF",
        "mZgHC4xUKt3R",
        "tnc7rHp3K-lM",
        "dlyBA-c3LHBE",
        "PBO-O8wqBnt4",
        "vtf-FraaBqhX",
        "XGDeaFlv2pXn",
        "PiFGpYMa-RIt",
        "LgXFXEo3aklL",
        "47CKeJ0hanrN",
        "P7V8xgOHasa7",
        "1713PVORbMT1",
        "EqYWh--Rv6hb",
        "kwwfPwBNbZZ7",
        "7T00ZeSVbjsG",
        "TSLM_odcZ8nr",
        "SnMq-Wj8Z_gk",
        "2jJrpO0ibNZL",
        "RTSEnAmWw4vn",
        "Ui0fjzeWbucT",
        "kKK77iB5cJ6g",
        "XNbzbDQ-faCX",
        "0oP9qx3F-FrZ"
      ],
      "authorship_tag": "ABX9TyOmskrbFk+pyDaaixRipDl4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}